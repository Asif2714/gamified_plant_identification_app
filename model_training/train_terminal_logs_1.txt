PS D:\Files\QMUL Docs\_Final Year\Final Year Project\plantnet_300K> python main.py --lr=0.01 --batch_size=32 --mu=0.0001 --n_epochs=30 --epoch_decay 20 25 --k 1 3 5 10 --model=resnet18 --pretrained --seed=4 --image_size=256 --crop_size=224 --root='.\images' --save_name_xp=xp1
Seed:    4
C:\Users\asifa\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\asifa\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
USING GPU
args.k :  [1, 3, 5, 10]
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [16:15<00:00,  7.81it/s]
val:   0%|                                                                                     | 0/973 [00:00<?, ?it/s]D:\Files\QMUL Docs\_Final Year\Final Year Project\plantnet_300K\epoch.py:79: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  batch_proba = F.softmax(batch_output_val)
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:21<00:00,  6.86it/s]

epoch 0 took 1138.27
loss_train : 2.0251884761522274
loss_val : 1.7327662852933867
acc_train : 0.5540144967939783 / topk_acc_train : {1: 0.5540144967939783, 3: 0.7354335098968497, 5: 0.7957616556519458, 10: 0.8581273881172207}
acc_val : 0.5960215952182016 / topk_acc_val : {1: 0.5960215952182016, 3: 0.7972234719454978, 5: 0.8523041326563404, 10: 0.9016646314030464} / avgk_acc_val : {1: 0.6150459541101613, 3: 0.8212931422327913, 5: 0.8702680120830387, 10: 0.9151937785204705}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:29<00:00,  8.20it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:25<00:00,  6.67it/s]

epoch 1 took 1095.59
loss_train : 1.3510860306435888
loss_val : 1.3725465539490245
acc_train : 0.6683612391151053 / topk_acc_train : {1: 0.6683612391151053, 3: 0.8417856967152626, 5: 0.888244313616163, 10: 0.9303571721412289}
acc_val : 0.6737900893373611 / topk_acc_val : {1: 0.6737900893373611, 3: 0.844205925830709, 5: 0.8880390770615079, 10: 0.9282408895173212} / avgk_acc_val : {1: 0.686965743299698, 3: 0.8703644193071535, 5: 0.9098913811941641, 10: 0.945015746513272}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:22<00:00,  8.26it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:24<00:00,  6.72it/s]

epoch 2 took 1086.77
loss_train : 1.1550595884254615
loss_val : 1.2831687703422068
acc_train : 0.706177536528969 / topk_acc_train : {1: 0.706177536528969, 3: 0.8718001279128881, 5: 0.9124411682710442, 10: 0.947453221600879}
acc_val : 0.691850375988174 / topk_acc_val : {1: 0.691850375988174, 3: 0.8580242946204769, 5: 0.899897165627611, 10: 0.9355035670672922} / avgk_acc_val : {1: 0.7048974869850247, 3: 0.8846648242174947, 5: 0.9213959766051802, 10: 0.9526640529597018}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:30<00:00,  8.19it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:27<00:00,  6.60it/s]

epoch 3 took 1098.19
loss_train : 1.045807381090421
loss_val : 1.2255221855799847
acc_train : 0.7273159612325555 / topk_acc_train : {1: 0.7273159612325555, 3: 0.8887813837550632, 5: 0.926560783220453, 10: 0.9570097902556618}
acc_val : 0.7042226364162221 / topk_acc_val : {1: 0.7042226364162221, 3: 0.8652869721704479, 5: 0.9047817983160872, 10: 0.9396490777042227} / avgk_acc_val : {1: 0.7135098656726011, 3: 0.8915740086123787, 5: 0.9252844013111382, 10: 0.9568416993380038}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:21<00:00,  8.27it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:26<00:00,  6.66it/s]

epoch 4 took 1086.73
loss_train : 0.9706080906822343
loss_val : 1.1873731553677178
acc_train : 0.7422391315042883 / topk_acc_train : {1: 0.7422391315042883, 3: 0.9002771445907608, 5: 0.9349366175240656, 10: 0.9629872579084603}
acc_val : 0.7110996850697345 / topk_acc_val : {1: 0.7110996850697345, 3: 0.8706536409794974, 5: 0.9108233176939392, 10: 0.9436339096342953} / avgk_acc_val : {1: 0.7227006877048654, 3: 0.8975191207661161, 5: 0.9303297127064721, 10: 0.959701780320072}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:21<00:00,  8.27it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:27<00:00,  6.62it/s]

epoch 5 took 1088.46
loss_train : 0.9150736488399934
loss_val : 1.163576890932925
acc_train : 0.7532470194657177 / topk_acc_train : {1: 0.7532470194657177, 3: 0.908558684137162, 5: 0.9419554272782433, 10: 0.9675421046589809}
acc_val : 0.7185873128093065 / topk_acc_val : {1: 0.7185873128093065, 3: 0.8739957580821389, 5: 0.9132013625554342, 10: 0.9452406967028729} / avgk_acc_val : {1: 0.7285172568931165, 3: 0.9011504595411016, 5: 0.9334468796195128, 10: 0.9616299248023652}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:04<00:00,  8.42it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:21<00:00,  6.87it/s]

epoch 6 took 1067.02
loss_train : 0.8700116635369867
loss_val : 1.1177298961659519
acc_train : 0.7624920054444972 / topk_acc_train : {1: 0.7624920054444972, 3: 0.9151429180537562, 5: 0.9474327227406156, 10: 0.9711007068007019}
acc_val : 0.7239539816183559 / topk_acc_val : {1: 0.7239539816183559, 3: 0.8826081367697153, 5: 0.9204640401054053, 10: 0.9507359084774085} / avgk_acc_val : {1: 0.7348479979433126, 3: 0.9087023587634167, 5: 0.9387814126871907, 10: 0.9647792274567775}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:34<00:00,  8.15it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:26<00:00,  6.66it/s]

epoch 7 took 1100.88
loss_train : 0.835539589197859
loss_val : 1.144889393798363
acc_train : 0.7713024155856935 / topk_acc_train : {1: 0.7713024155856935, 3: 0.9202553338034405, 5: 0.9510364223749159, 10: 0.973626166385149}
acc_val : 0.7205475930329712 / topk_acc_val : {1: 0.7205475930329712, 3: 0.8790732052188444, 5: 0.9167684298476766, 10: 0.9489363069606016} / avgk_acc_val : {1: 0.7302525869271804, 3: 0.904428305161, 5: 0.9374959830323285, 10: 0.963654476508773}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:35<00:00,  8.15it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:28<00:00,  6.56it/s]

epoch 8 took 1104.01
loss_train : 0.8070640656593684
loss_val : 1.082452863424158
acc_train : 0.7755989766968957 / topk_acc_train : {1: 0.7755989766968957, 3: 0.9249167746273307, 5: 0.9544884304432674, 10: 0.9758933403302776}
acc_val : 0.7324699530818176 / topk_acc_val : {1: 0.7324699530818176, 3: 0.8889710135612828, 5: 0.9235490712770743, 10: 0.9529854103734173} / avgk_acc_val : {1: 0.7422392184587698, 3: 0.9127193264348609, 5: 0.945015746513272, 10: 0.9683784304903914}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:02<00:00,  8.45it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:25<00:00,  6.68it/s]

epoch 9 took 1067.68
loss_train : 0.7802964371197244
loss_val : 1.1727169493956822
acc_train : 0.7816707391069057 / topk_acc_train : {1: 0.7816707391069057, 3: 0.9289222519227931, 5: 0.9574525656373506, 10: 0.9778448318273504}
acc_val : 0.7101034770872164 / topk_acc_val : {1: 0.7101034770872164, 3: 0.8730959573237355, 5: 0.9135548557105212, 10: 0.9458512757889325} / avgk_acc_val : {1: 0.7223150588084067, 3: 0.9006684234205283, 5: 0.9343145446365447, 10: 0.9622726396297963}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:49<00:00,  8.03it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:28<00:00,  6.55it/s]

epoch 10 took 1117.99
loss_train : 0.7597777787268521
loss_val : 1.1251909142291103
acc_train : 0.7850489512783089 / topk_acc_train : {1: 0.7850489512783089, 3: 0.9308819429639712, 5: 0.9596910411781105, 10: 0.9793043506781023}
acc_val : 0.7247252394112732 / topk_acc_val : {1: 0.7247252394112732, 3: 0.8817404717526833, 5: 0.9198534610193457, 10: 0.9511536731152388} / avgk_acc_val : {1: 0.7360691561154316, 3: 0.9087987659875313, 5: 0.9400025708593097, 10: 0.9659361141461533}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:46<00:00,  8.05it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:25<00:00,  6.69it/s]

epoch 11 took 1111.14
loss_train : 0.7383141747490842
loss_val : 1.1246278133595922
acc_train : 0.7903622558585742 / topk_acc_train : {1: 0.7903622558585742, 3: 0.934506141458535, 5: 0.9617819249249742, 10: 0.9802677971104806}
acc_val : 0.7209332219294299 / topk_acc_val : {1: 0.7209332219294299, 3: 0.8826724082524584, 5: 0.9202712256571759, 10: 0.951860659425413} / avgk_acc_val : {1: 0.7330483964265055, 3: 0.9090237161771322, 5: 0.9409023716177132, 10: 0.9663538787839836}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:12<00:00,  8.36it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:26<00:00,  6.64it/s]

epoch 12 took 1077.76
loss_train : 0.7223810401587029
loss_val : 1.093867832250556
acc_train : 0.7929410124797062 / topk_acc_train : {1: 0.7929410124797062, 3: 0.9374005805277227, 5: 0.9640081011495761, 10: 0.9820470981813412}
acc_val : 0.7304775371167813 / topk_acc_val : {1: 0.7304775371167813, 3: 0.8879105340960216, 5: 0.9243846005527347, 10: 0.9523748312873578} / avgk_acc_val : {1: 0.7403753454592198, 3: 0.9110482678835401, 5: 0.9417057651520021, 10: 0.967478629731988}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:01<00:00,  8.46it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:27<00:00,  6.61it/s]

epoch 13 took 1069.55
loss_train : 0.7045255841306581
loss_val : 1.1515891267438976
acc_train : 0.7973441676642778 / topk_acc_train : {1: 0.7973441676642778, 3: 0.9395037635907444, 5: 0.9655168172649601, 10: 0.9828752521359813}
acc_val : 0.7226042804807506 / topk_acc_val : {1: 0.7226042804807506, 3: 0.8810013497011376, 5: 0.9193071534160293, 10: 0.9502217366154637} / avgk_acc_val : {1: 0.7331769393919918, 3: 0.9054887846262614, 5: 0.9369175396876406, 10: 0.9649720419050067}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:12<00:00,  8.35it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:26<00:00,  6.65it/s]

epoch 14 took 1078.91
loss_train : 0.6897296105670088
loss_val : 1.097400550059821
acc_train : 0.8010790600042638 / topk_acc_train : {1: 0.8010790600042638, 3: 0.9416397448301874, 5: 0.9668410436379737, 10: 0.9839862903622558}
acc_val : 0.733016260685134 / topk_acc_val : {1: 0.733016260685134, 3: 0.8874927694581914, 5: 0.9251879940870236, 10: 0.9544957902178803} / avgk_acc_val : {1: 0.7438460055273475, 3: 0.912783597917604, 5: 0.9431840092550935, 10: 0.9673822225078732}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:23<00:00,  8.26it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:25<00:00,  6.68it/s]

epoch 15 took 1088.99
loss_train : 0.679142947427731
loss_val : 1.1194838718377023
acc_train : 0.8034077305301826 / topk_acc_train : {1: 0.8034077305301826, 3: 0.9429188737106217, 5: 0.9679233834598796, 10: 0.9847406484199479}
acc_val : 0.7227006877048654 / topk_acc_val : {1: 0.7227006877048654, 3: 0.8860466610964715, 5: 0.924223921845877, 10: 0.9535317179767338} / avgk_acc_val : {1: 0.7322771386335882, 3: 0.911273218073141, 5: 0.9430554662896073, 10: 0.9671894080596439}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:36<00:00,  8.14it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:29<00:00,  6.52it/s]

epoch 16 took 1106.17
loss_train : 0.6627142713122935
loss_val : 1.121120763229735
acc_train : 0.8072287180832746 / topk_acc_train : {1: 0.8072287180832746, 3: 0.9458830089047049, 5: 0.9696739861263713, 10: 0.9852777185588482}
acc_val : 0.7285172568931165 / topk_acc_val : {1: 0.7285172568931165, 3: 0.8862716112860723, 5: 0.921556655312038, 10: 0.952503374252844} / avgk_acc_val : {1: 0.7399897165627611, 3: 0.9084131370910727, 5: 0.9403560640143969, 10: 0.9658397069220387}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:29<00:00,  8.20it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:27<00:00,  6.60it/s]

epoch 17 took 1095.85
loss_train : 0.6544555998699335
loss_val : 1.1159200093444483
acc_train : 0.8090408173305564 / topk_acc_train : {1: 0.8090408173305564, 3: 0.9465266731169747, 5: 0.9705882352941176, 10: 0.9861878679545417}
acc_val : 0.7260106690661353 / topk_acc_val : {1: 0.7260106690661353, 3: 0.8858859823896137, 5: 0.923645478501189, 10: 0.9541101613214217} / avgk_acc_val : {1: 0.7361655633395462, 3: 0.9115303040041134, 5: 0.9434410951860659, 10: 0.9669001863872999}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:26<00:00,  8.23it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:26<00:00,  6.65it/s]

epoch 18 took 1092.88
loss_train : 0.641326329369529
loss_val : 1.1217446676436276
acc_train : 0.8127060135456469 / topk_acc_train : {1: 0.8127060135456469, 3: 0.9481337837616228, 5: 0.971891962806868, 10: 0.9863846570130701}
acc_val : 0.7298669580307218 / topk_acc_val : {1: 0.7298669580307218, 3: 0.8846326884761232, 5: 0.9207532617777492, 10: 0.9517642522012982} / avgk_acc_val : {1: 0.7405360241660776, 3: 0.908605951539302, 5: 0.9401632495661675, 10: 0.9668037791631853}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:12<00:00,  8.35it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:32<00:00,  6.40it/s]

epoch 19 took 1081.18
loss_train : 0.6315941025188466
loss_val : 1.1185229894831592
acc_train : 0.8151289788287771 / topk_acc_train : {1: 0.8151289788287771, 3: 0.9500852752586956, 5: 0.9728062119746143, 10: 0.9876350874891356}
acc_val : 0.7310881162028408 / topk_acc_val : {1: 0.7310881162028408, 3: 0.8859181181309853, 5: 0.9229706279323864, 10: 0.9541422970627932} / avgk_acc_val : {1: 0.7411787389935086, 3: 0.9107269104698246, 5: 0.9396812134455942, 10: 0.9652612635773508}
epoch:  67%|██████████████████████████████████████████████                       | 20/30 [6:04:14<3:01:34, 1089.42s/it]Switching lr to 0.001
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:17<00:00,  8.31it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:23<00:00,  6.78it/s]

epoch 20 took 1081.14
loss_train : 0.3738944314071252
loss_val : 0.8987755097924068
acc_train : 0.8879901277488972 / topk_acc_train : {1: 0.8879901277488972, 3: 0.97877957985536, 5: 0.9894594860525755, 10: 0.9952770625953197}
acc_val : 0.7777813484157079 / topk_acc_val : {1: 0.7777813484157079, 3: 0.9142297062793239, 5: 0.9436017738929237, 10: 0.9667073719390706} / avgk_acc_val : {1: 0.7860723696895687, 3: 0.9395848062214796, 5: 0.9608908027508195, 10: 0.9777942027122566}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:16<00:00,  8.32it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:25<00:00,  6.69it/s]

epoch 21 took 1081.96
loss_train : 0.3128755652074214
loss_val : 0.8987755824355677
acc_train : 0.906873677823513 / topk_acc_train : {1: 0.906873677823513, 3: 0.9848964397579495, 5: 0.9925384148641335, 10: 0.9967775791665984}
acc_val : 0.7791953210360563 / topk_acc_val : {1: 0.7791953210360563, 3: 0.9148724211067549, 5: 0.9445658461340704, 10: 0.9672536795423871} / avgk_acc_val : {1: 0.7861366411723119, 3: 0.9392955845491355, 5: 0.9623047753711678, 10: 0.9780834243846006}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [14:55<00:00,  8.51it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:28<00:00,  6.54it/s]

epoch 22 took 1065.50
loss_train : 0.28360494218250565
loss_val : 0.9038847849662166
acc_train : 0.9157332852293413 / topk_acc_train : {1: 0.9157332852293413, 3: 0.9875120943275554, 5: 0.9942439200380458, 10: 0.9974950392758163}
acc_val : 0.7777813484157079 / topk_acc_val : {1: 0.7777813484157079, 3: 0.9142618420206954, 5: 0.9451442894787583, 10: 0.9668037791631853} / avgk_acc_val : {1: 0.7858795552413395, 3: 0.9391670415836494, 5: 0.9620155536988239, 10: 0.9772478951089402}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:27<00:00,  8.22it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:25<00:00,  6.69it/s]

epoch 23 took 1092.90
loss_train : 0.26448106177872605
loss_val : 0.9094155237630561
acc_train : 0.9216164581249282 / topk_acc_train : {1: 0.9216164581249282, 3: 0.9890905065678348, 5: 0.9950392758162646, 10: 0.9979214155692944}
acc_val : 0.7773635837778777 / topk_acc_val : {1: 0.7773635837778777, 3: 0.9141654347965807, 5: 0.943794588341153, 10: 0.9658397069220387} / avgk_acc_val : {1: 0.7848512115174497, 3: 0.9392955845491355, 5: 0.9608586670094479, 10: 0.9775371167812842}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:46<00:00,  8.05it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:11<00:00,  7.38it/s]

epoch 24 took 1098.13
loss_train : 0.24738106433457588
loss_val : 0.9203070101745948
acc_train : 0.9274955312484626 / topk_acc_train : {1: 0.9274955312484626, 3: 0.9904147329408485, 5: 0.9957690352416405, 10: 0.9982329982452975}
acc_val : 0.7762709685712449 / topk_acc_val : {1: 0.7762709685712449, 3: 0.9138762131242367, 5: 0.9444694389099556, 10: 0.9664502860080982} / avgk_acc_val : {1: 0.7844977183623626, 3: 0.9378816119287872, 5: 0.9601838164406453, 10: 0.9763159586091651}
epoch:  83%|█████████████████████████████████████████████████████████▌           | 25/30 [7:34:33<1:30:39, 1087.88s/it]Switching lr to 0.0001
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:11<00:00,  8.37it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:10<00:00,  7.45it/s]

epoch 25 took 1062.24
loss_train : 0.22303372199007593
loss_val : 0.9168431560658379
acc_train : 0.9362362452647632 / topk_acc_train : {1: 0.9362362452647632, 3: 0.992066941078076, 5: 0.9963389035569622, 10: 0.9984953836566687}
acc_val : 0.7786811491741115 / topk_acc_val : {1: 0.7786811491741115, 3: 0.9150330998136127, 5: 0.945015746513272, 10: 0.9664824217494697} / avgk_acc_val : {1: 0.7864901343273989, 3: 0.9385243267562182, 5: 0.9607943955267048, 10: 0.9767658589883669}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:14<00:00,  8.33it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:26<00:00,  6.66it/s]

epoch 26 took 1081.73
loss_train : 0.22006432845214946
loss_val : 0.9163706787850385
acc_train : 0.937207891241247 / topk_acc_train : {1: 0.937207891241247, 3: 0.992206333327867, 5: 0.9964700962626478, 10: 0.9985732793256695}
acc_val : 0.7777813484157079 / topk_acc_val : {1: 0.7777813484157079, 3: 0.9146153351757825, 5: 0.9440516742721254, 10: 0.9662253358184973} / avgk_acc_val : {1: 0.7859438267240825, 3: 0.9387814126871907, 5: 0.9602159521820168, 10: 0.9765730445401375}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:53<00:00,  7.99it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:23<00:00,  6.76it/s]

epoch 27 took 1117.60
loss_train : 0.2180707276691503
loss_val : 0.9173911844797954
acc_train : 0.9376506666229357 / topk_acc_train : {1: 0.9376506666229357, 3: 0.9923170271732892, 5: 0.9965520917037013, 10: 0.9985691795536168}
acc_val : 0.7768494119159329 / topk_acc_val : {1: 0.7768494119159329, 3: 0.9146153351757825, 5: 0.9446943890995565, 10: 0.9669001863872999} / avgk_acc_val : {1: 0.785911690982711, 3: 0.9385243267562182, 5: 0.96028022366476, 10: 0.9770229449193393}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [15:41<00:00,  8.10it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:31<00:00,  6.44it/s]

epoch 28 took 1113.45
loss_train : 0.21591798447016788
loss_val : 0.9221128739278626
acc_train : 0.9384419226291019 / topk_acc_train : {1: 0.9384419226291019, 3: 0.992407222158448, 5: 0.9966217878285968, 10: 0.9984625854802472}
acc_val : 0.7779420271225658 / topk_acc_val : {1: 0.7779420271225658, 3: 0.9148402853653834, 5: 0.9445015746513272, 10: 0.966032521370268} / avgk_acc_val : {1: 0.7861687769136834, 3: 0.938685005463076, 5: 0.9601516806992737, 10: 0.975962465454078}
train: 100%|███████████████████████████████████████████████████████████████████████| 7623/7623 [16:49<00:00,  7.55it/s]
val: 100%|███████████████████████████████████████████████████████████████████████████| 973/973 [02:08<00:00,  7.59it/s]

epoch 29 took 1155.76
loss_train : 0.2140497556036889
loss_val : 0.921652782731402
acc_train : 0.9392167795470572 / topk_acc_train : {1: 0.9392167795470572, 3: 0.9926655077977664, 5: 0.9966914839534922, 10: 0.9985814788697749}
acc_val : 0.7772993122951346 / topk_acc_val : {1: 0.7772993122951346, 3: 0.9147117423998972, 5: 0.9446943890995565, 10: 0.9660003856288965} / avgk_acc_val : {1: 0.7850761617070506, 3: 0.9388135484285622, 5: 0.9600874092165306, 10: 0.9765087730573945}
epoch: 100%|███████████████████████████████████████████████████████████████████████| 30/30 [9:06:44<00:00, 1093.48s/it]

test:   0%|                                                                                    | 0/973 [00:00<?, ?it/s]D:\Files\QMUL Docs\_Final Year\Final Year Project\plantnet_300K\epoch.py:154: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  batch_proba_test = F.softmax(batch_output_test)
test: 100%|██████████████████████████████████████████████████████████████████████████| 973/973 [02:18<00:00,  7.04it/s]
PS D:\Files\QMUL Docs\_Final Year\Final Year Project\plantnet_300K>